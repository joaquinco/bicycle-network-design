# Notas de interés

Notas que caen fuera del documento latex.

## 27/07/21

He estado comparando los cuatro modelos .mod contra las caracteristicas de una solucion que describi en el documento. Me pasa que si uso cbc, los modelos v3 y v4 dan errores, pero no pasa con glpsol. Los modelos v3 y v4 tienen la implementacion de f_k v3.

Habria que intentar arreglar CBC porque anda mas rapido y soporta multithread para branch and cut.

Al usar glpsol, correr varias instancias aleatorias de Sioux Falls, el v4 da valores objetivos differente al resto, lo cual me resulta extraño.

Luego de analizar los datos de las 2000 ejecuciones con glpsol en el cluster, dado que el v4 es el que mas normalmente da distinto (distinto valor de demanda transferida total), lo exclui y mire las veces en que el v3 da distinto al default y v2 (estos dos siempre dan igual), lo que me pasa es que al correr esos casos de manera local me dan los tres lo mismo (default, v2 y v3). Tampoco pude reproducir corriendolo manualmente en el cluster, por lo que agregue mas datos a los logs, baje glpsol en su version 4.65 (antes 4.52.1) y ejecute de nuevo la comparacion.

## 03/08/21

Ver si hay alguna forma de exportar .mod y .dat a algun otro formato (me suena que glpk tiene algo) y si cbc soporta alguna de esas formas. Esto con el fin de mejorar el desempeño, porque glpsol es mucho mas lento que cbc.

## 09/08/21

Vale la pena averiguar por que el single_level_v4 anduvo mal? Teoricamente, si f cumple con la definicion deberia dar el valor de demanda transferida iguales a los otros modelos.

## 14/08/21

Despues de analizar un poco las versiones v3 y v4 (principalmente la ultima que es la que mas difiere), me doy cuenta que la formulación da mal porque al dividir waux[k, j] + wsink[k, j] = w[k] y utilizar un valor muy alto de INFINITE para limitar waux y wsink, puede causar que aunque uno de ellos deba estar en 0, su valor pueda ser un 0.000X > 0. Esto pasa con glpsol en algunas instancias, el tipo de validacion que falla es de "demand transfered". Utilizando un valor de INFINITE mas bajo (tipo 99) el v4 me dio correcto para la instancia que estaba analizando. Esto no quita que el v3 y v4 sigan siendo mucho mas lentos que v1 y v2. Con cbc resuelve correctamente la instancia con v4. En la nota del 21/07 dice que con cbc algunas instancias v3 y v4 dan errores, pero lamentablemente no anote que tipo de error da, porque es sabido que v2 y v4 dan errores de budget (o path not optimized) en alguno casos.

Importante: averiguar cual era el error por el que deje de usar cbc.

## 17/08/21

Ejecute 1000 instancias aleatorias con cbc, los modelos v1 y v3 no dieron ningun error, menos una instancia que estaba mal formada (dos breakpoints casi consecutivos, todas dieron error de "demand transfered" aca). Los modelos v2 y v4 al no tener las variables de holgura r no optimizan del todo los caminos entonces dan los errores de budget (o path not optimized).

Iba a terminar esta parte hoy, pero descubri que no estoy guardando todas las instancias (solo los que obtienen soluciones erroneas), entonces al investigar los que dieron diferencia en la cantidad de demanda transferida local no estaban.

Nota: todavia no se que es lo que andaba mal de cbc hace un tiempo.

## 18/08/21

Ejecute 1000 instancias de nuevo (comparison 6), guardando todas las solcuiones y todos las instancias.
Detecte un caso en que los modelos con variables de resto dan una solucion incorrecta, y es cuando para un par origen destino, la demanda transferida es chica (comparable al valor de la variable de resto). En este caso el modelo con variables de resto puede dar soluciones incorrectas. Sabiendo esto, lo ideal seria tener dos modelos, ejecutar el v2 optimizando la demanda transferida y definir el rango del costo del camino mas corto de cada par origen destino. Luego fijando esto, correr otro problema que optimice la construccion de ciclovias. Otra solucion es, multiplicar las variables de resto en la funcion objetivo por una constante chica de manera que sean insignificantes respecto a los valores de demanda transferida.

Las instancias problematicas fueron:
651: hay dos breakpoints que estan muy pegados, todas las versiones dieron error.
726: problemas al usar variables de resto y demanda transferida muy baja (o de magnitud comparable).
844: el v2 y v4 dieron demanda transferida incorrecta para un par od en el cluster pero local anduvo bien.
910: el v2 dio cantidad diferente de demanda transferida en el cluster pero no al ejecutarlo local.

651 y 844 los diagnostico a problema numerico.
726 es un problema ya identificado mas arriba.
910: caso sin resolver. Para el od_0 el v2 devolvio un j = 1, mientras que el v3 (por ej) fue j = 2. Ambas versiones encontraron un camino mas corto de 17.28, dado que los puntos de quiebre mas cercanos son: `1  17.525012726598575  2  17.408854811461072  3  17.273638070345033` se deduce que el valor correcto de j es 2, por lo tanto parece haber habido un error en la ejecucion en el cluster. Nótese que subsecuentes ejecuciones en el cluster dieron el resultado correcto, por lo tanto se cataloga como irreproducible deterministicamente.

## 01/09/21

Encontre un error en la funcion calculate_construction_cost (devolvia el doble de lo que tenia que dar para infras mayor a 0). Deberia correr las 1000 de nuevo.

(ya lo agregué) IMPORTANTE: recien me doy cuenta, que hay que detallar algunas consideraciones respecto a las infrastructuras de bicicleta:
- Considero infrastructuras dirigidas: es decir que puedo construir en una sola direccion.
- Si construyo en dos direcciones no hay consideracion respecto a la reduccion en costo de construir la segunda (o dicho de otra manera, las dos juntas).
- Se puede construir una infrastructura en un sentido y otra en otro.

## 03/09/21

Notas de la lectura del paper The Bicycle Network Improvement Problem: Optimization Algorithms and A Case Study in Atlanta:

- Me falta agregar una seccion de motivacion del problema, trabajo previo y una buena introduccion de a poquito a como se realizo el trabajo. Tambien plantear si aplica, el aporte del trabajo, o la diferencia entre el problema/solucion a otros trabajos similares.
- En este trabajo se consideran arcos unsafe 
- La funcion de demanda transferida se basa en un parametro L (para cada od) que actua como threashold a partir del cual se considera que toda la demanda se transfiere. Ademas se agrega la restricción de que el camino tiene que ser "safe", concepto que yo no manejo en mi problema.
- Analizar si puede encontrarse alguna equivalencia entre los modelos a menos del concepto de safe/unsafe. Me parece que usando una funcion de penalidad como D^k_tot - f_k(w_k) donde D^k_tot es la demanda total del par k, podria asimilarse bastante.
- Hay cierta similitud en el modelado de una funcion f que en el caso de este paper lo hacen como funciones lineales de a pedazos, o peasewise linear funtions.

## 07/09/21

Estuve revisando el documento. Me di cuenta que la formulación de un nivel es como la formulación multiobjetivo de Pareto pero ponderando el primer nivel con 1 y el segundo con 0. Esto me lleva a pensar que las variables de resto que puse fueron al pedo y pude haberlo hecho con la variable w_k directamente, posiblemnete ponderada por un factor chico en vez de cero.

Deje ejecutando en el cluster 1000 instancias random de sioux-falls ahora con dos formulaciones mas, seria con multiobjetivo de Pareto con ponderacion 1 y 1 (cada funcion objetivo) y las dos versiones de la formulacion de f_k.

## 14/09/21

Luego de ver las ejecuciones de las 6 versiones de la formulación, con fecha 11/09/21, vi que demoran mas, me parece que es por el fix de la funcion get_construction_cost que hice hace un tiempo (despues de haber corrido las 1000 instancias la vez anterior). Probe correr la misma instancia de nuevo en el cluster (un ejemplo para una formulación) y demoró bastante mas.

## 18/09/21

Voy a ejecutar las 1000 instancias de nuevo porque la formulación v6 tenia mal la funcion objetivo (el w_k no estaba negado). Notese que el v6 habia demorado mucho mas que el resto (muchisimo mas), y habia dado errores contrario a lo que se esperaria (que se comporte igual que el v5). Esto seguro tuvo que ver con la ejecucion mas lenta de todas las instancias que analice el 14/09/21.

## 23/09/21

- Leer paper que mando Antonio y el del inco sobre BLOS y como hicieron el analisis y validacion en el del inco.

## 18/10/21

- Estoy mejorando la introduccion del documento. Me faltan referencias para lo beneficioso de andar en bicicleta, en particular para uruguay. Tambien tendria que agregar algo de trabajo relacionado.
- Sobre la perturbacion de parametros: para generar valores de P y Q necesitaria alguna funcion de transferencia de demanda, buscar algun paper. En la literatura parece llamarse "modal shift" o "modal shift":
  - https://transportgeography.org/contents/chapter5/transportation-modes-modal-competition-modal-shift/
  - https://transportgeography.org/contents/chapter5/transportation-modes-modal-competition-modal-shift/modal-shift-principles/
  - Otros papers que recopile en pdf.

## 21/10/21

- Estoy escribiendo la parte de especificación de datos. Los datos de BLOS de Zhu & Zhu me parece que son cualquiera, en el manual del BLOS y en el Highway capacity manual esta diferentes (e iguales entre ellos).

## 11/11/21

- Tengo que escribir una seccion parecia a la primera parte del caitulo 6 del libro Modeling Transport de Ortuzar, que habla de modal split.
- Al dibujar los flujos, tienen que ser ponderados por la demanda transferida je.

## 17/11/21

- Analizando por arriba las soluciones, las instancias con la funcion happy (o concave up) no transfieren demanda porque el salto al primer breakpoint es muy grande.
- En la seccion de resultados del analisis de sensibilidad, puedo:
  * comparar los puntos de quiebre elegidos para cada funcion dependiendo del presupuesto y de la cantidad de puntos de quiebre.
  * comparar el presupuesto por tipo de infrastructura dependiendo.
  * analizar la transferencia de demanda en base a la forma de la función de transferencia (en base al primer punto).
  * Dibujar algunos casos relevantes.
- Para las instancias que dieron timeout deberia reportar el gap: el solver deberia reportarlo.

## 23/11/21

- Despues de correr todo, podria investigar las opciones del CBC o AMPL para tratar de mejorar las soluciones.

## 28/11/21

- Agregué el parámetro `inf` multiplicando a las variables `rest` en single_level.mod porque me paso que una instancia con pesupuesto suficiente para transferir el 100% de la demanda no lo hizo, luego si lo hizo con esta solucion.

## 30/11/21

- El parámetro inf ha dejalo al single_level.mod con un tiempo de ejecucion terrible, ademas mientras mas chico es su valor peor es el desempeño. Tuve que agregar un metacalculo metaconvincente para hacerlo dinamico y no tan bajo.
- En base a esto tendria que hacer otra iteracion del analisis de desempeño/validacion de implementacion con los modelos: default, v2 y v5 que fueron los mas rapidos.

## 02/12/21

- Luego de correr v1, v2 y v5 con random models con 4 infrastructuras (en vez de dos como antes) hubo un caso en que el problema del v1 se repitio: esta vez porque los valores de demanda eran mucho mas grandes que los valores de camino mas corto, entoces el parametro inf quedo de 10, no habria problema si no fuera por que el epsilon elegido fue 1e-5 que es relativamente muy chico para que se cumpla la condicion debido al uso de punto flotante, claro.

## 06/12/21

- Ejecute las mismas instancias con 12.4 de budget_factor y funciones de transferencia lineal y logit, la lineal transfirio el 100% de la demanda mientras que la logit el 90%. El problema fue que la funcion logistica no va exactamente desde 0 a 1 sino que es menos, ademas al utilizar enteros en los valores de demanda se perdio por redondeo entre 1 y 2 unidades de demanda en el ultimo punto de quiebre (el elegido dado que hay mucho presupuesto), por lo tanto este fue el problema.
- En base a lo anterior, capaz deberia computar los porcentages en funcion del total de demanda transferible.

## 07/12/21

- He descubierto que la version de cbc del cluster no era parallela, la compile bien de nuevo (version 2.10.5 con --enable-cbc-parallel). Ahora puse a
correr el anali de sensibilidad de nuevo.

## 13/12/21

- He descubierto que CPLEX es muchisimo mas rapido que CBC, incluse corriendo en una maquina de escritorio con menos recursos ? que los que tenia CBC en el cluster (tengo que probar correr CBC con un problema a la vez con todos los recursos). Habia una instancia que no ejecutaba (el proceso era matado por falta de memoria creo), recien me di cuenta que estaba pasando mal la opcion de `options cplex_options '...';` en ampl.

# 15/12/21

- Tengo que preguntarle la undiad en que estan las coordenadas de los nodos de montevideo asi filtro por distancia entre nodos.

# 19/12/21

- Resulta que limitar la memoria que utiliza el arbol del MIP (en cplex) es una stop condition. Por eso, en el analisis de sensibilidad, la instancia que llego a esta condicion tenia un gap < 1% pero mayor al por defecto de CPLEX (que es minusculo).
- Para las instancias de montevideo, solucione un problema que no estaba filtrando los pares origen destino entonces usaba los seis mil y pico, si sigue dando out of memory, probare cambiar la estrategia de seleccion del nodo en el arbol y la estrategia de seleccion de la variable para hacer el branch.

# 29/12/21

- Segun los logs de CPLEX, en 4 dias no ha mejorado la primer solucion encontrada, lo unico que hace es acotarla mejor. Los dias pasados estuve matando esta ejecucion y probando otra forma de seleccion de variable y recorrido del arbol que encuentren mejores soluciones, ya que la observacion del principio fue hace varios dias. Lo que sucedio en estos casos fue que termina abrutamente por OOM, entonces no hay otra que ejecutarlo como ahora o reducir el tamaño de la instancia.

# 06/01/22

- Con la configuracion de nodesel y varsel de cplex que mejora el manejo de la memoria, igualmente el cplex se queda sin memoria. Pude ver en los logs que la ultima solucion encontrada tenia un gap del 14%, lo malo es que no se guardo la solucion antes de ser matado. Tengo que correr esto en el cluster o encontrar una forma de guardar la mejor solucion periodicamente para cuando sucede esto.
- TODO: Leer documentacion de ampl cplex que detalla las opciones con mas documentacion.

# 21/01/22

- Estoy usando bcnetwork y notebooks para dibujar los ejemplos. TODO: Tengo que cambiar la forma en que dibujo los pares origen destino porque no se entiende, mi idea es tener un conjunto de colores y otro de shapes e iterar sobre ellos para asignar a cada par origen destino un (color, shape) (UPDATE: ya esta hecho).

# 01/02/22

- Estaba escribiendo el documento y me di cuenta que es dificil escapar de la transformación a un nivel mediante las condiciones de KKT, en este momento no me entra en la cabeza asi que por ahora voy a argumentar que dicha transformación es más compleja que la propuesta dada la cantidad de variables enteras que hay que agregar.

# 03/02/22

- Pude escribir la transformacion de KKT y justificarme. Repaso de KKT para LP: Restricciones primal + variable de slack, restrccion dual + variable de slack e igualdad de objetivos primarl-dual. Luego, puedo utilizar el teorema de holgura complementaria y para reescribir la ultima ecuacion como un producto de factores que iguala a cero (ecuacion no lineal), que puedo reescribir como lineal utilizando un M grande y variables binarias.

# 27/02/22

- Parece que encontre la panacea en la configuracion de CPLEX, poner "benders strategy 3" (osea forzar a usar descomposicion de benders) mejora los tiempos de ejecucion increiblemente. Notar que no estoy usando las annotations que permite cplex para definir sobre que variables hacer la descomposicion.

# 07/03/22

- Decidi ejecutar varias versiones de montevideo, de las de 738 pares origen destino. Cree un directorio montevide_v2 y voy a reagendar los jobs en el cluster.

# 13/03/22

- Voy a agregar dos ejecuciones mas de montevideo con budgect factor de 0.4 porque con 0.8 y 1.6 la demanda transferida fue bastante alta.

# 25/06/22

- Vi que se estaban generando mal los puntos de quiebres de las instancias de montevideo, asi que arregle el error en runmontevide.py e hice que se normalice entre 0 y 1 el codominio en bc.model_utils.build_breakpoints.

# 22/07/22 - Segunda correccion

- Actualice el template de udelar, la diferencia fue que cambiaron el manejo de la bibliografia.
- El @book e @inbook se estan renderizando igual en las referencias (el ultimo sin informacion de capitulo o paginas).

### Cambios grandes pendientes:

- Cambiar notacion de subproblemas a x' in argmin ... Tengo que arreglar algunas frases en las que digo que la primer formulacion binivel presentada es lineal cuando no lo es.
- Versiones multiobjetivo (secc. 3.5): Al final hay una discusion que tengo que ampliar.
-  En la sec. 3.6.1 de resultados, en la segunda ronda de ejecuciones cuando explico el seteo del parametro beta: agregar unos comentarios mas.
- Breve parrafo con conclusiones despues de analisis de sensibilidad y aplicacion a una instancia realista.
- Arreglar bibliorafia: bajar citas completas.
